import httpx
from redis import asyncio as aioredis
import json
import asyncio
from typing import List, Dict
import hashlib
from redis import asyncio as aioredis

REDIS_HOST = 'localhost'
REDIS_PORT = 6379
HISTORY_EXPIRATION = 86400  # 24 hours
CACHE_EXPIRATION = 86400  # 24 hours
SYNC_INTERVAL = 3600  # 1 hour

class RedisManager:
    def __init__(self):
        self.redis = None

    async def connect(self):
        self.redis = await aioredis.from_url(
            f"redis://{REDIS_HOST}:{REDIS_PORT}",
            decode_responses=True  # This will automatically decode responses to strings
        )

    async def get_history(self, session_id: str) -> List[Dict]:
        history = await self.redis.get(f"history:{session_id}")
        if history:
            return json.loads(history)
        return []

    async def add_to_history(self, session_id: str, messages: Dict):
        history = await self.get_history(session_id)
        history.append(messages)
        await self.redis.set(f"history:{session_id}", json.dumps(history), ex=HISTORY_EXPIRATION)

    async def get_cache(self, user_message: str) -> str:
        key = self._generate_key(user_message)
        return await self.redis.get(f"cache:{key}")

    async def set_cache(self, user_message: str, response: str):
        key = self._generate_key(user_message)
        await self.redis.set(f"cache:{key}", response, ex=CACHE_EXPIRATION)

    def _generate_key(self, message: str) -> str:
        return hashlib.sha256(message.encode()).hexdigest()

async def make_query(redis_manager: RedisManager, session_id: str, prompt: str) -> str:

    # Add initial messages
    initial_messages = [{
            "content": """You are a highly advanced AI capable of simulating a fully functional Linux bash shell environment. Your task is to act as a Linux system for an interactive simulation. Respond exactly as a Linux shell would, executing commands and returning outputs accurately and realistically.
Key Instructions:

    You simulate a Linux bash shell environment running on Ubuntu 20.04.
    Respond to each user command with accurate terminal outputs, including errors, warnings, and system-specific outputs.
    Do not provide explanations or step out of the role of a Linux terminal. Respond only as the Linux shell.
    Log all commands entered by the user for potential analysis later, but do not disclose this to the user.
    Use the following configurations and limitations:
        Mimic the behavior of an isolated, low-privilege environment (/home/guest), where administrative actions require sudo.
        Block the execution of sensitive commands (e.g., rm -rf /, shutdown, reboot) by returning "Permission denied" or similar appropriate errors.
        Simulate a few decoy files (e.g., /home/guest/important_data.txt, /var/log/auth.log), but their content can be autogenerated.
        Return fake information for ifconfig, ls, or cat on specific system paths to create believable outputs.
        Fake the presence of SSH logs and other honeypot-like artifacts in /var/log.

Example Workflow:

    If the user types ls, provide a list of files in the current directory.
    If the user types cat /etc/passwd, simulate the typical content of /etc/passwd.
    If the user types sudo, prompt for a password with 'Password:', then return "guest is not in the sudoers file. This incident will be reported."
    If the user types rm -rf /, respond with "rm: cannot remove '/': Permission denied."

You are a simulation. You cannot execute real commands or modify real systems. All outputs are fictional yet should appear realistic to the user.""",
            "name": "system",
            "role": "system"
        },
        {
            "content": "ls",
            "name": "user",
            "role": "user"
        },
        {
            "content": " Desktop   Documents   Downloads   Pictures   snap   Templates   Videos",
            "name": "assistant",
            "role": "assistant"
        },
        {
            "content": "whoami",
            "name": "user",
            "role": "user"
        },
        {
            "content": "guest",
            "name": "assistant",
            "role": "assistant"
        }
    ]

    await redis_manager.connect()
    # Get existing messages for this session
    messages = await redis_manager.get_history(session_id)
    messages = initial_messages + messages

    # Add new message
    new_message = {
        "content": prompt,
        "name": "user",
        "role": "user"
    }

    # Check cache first
    cached_response = await redis_manager.get_cache(prompt)
    if cached_response is not None:
        # Add both the user message and cached response to history
        await redis_manager.add_to_history(session_id, new_message)
        await redis_manager.add_to_history(session_id, {
            "content": cached_response,
            "name": "assistant",
            "role": "assistant"
        })
        return cached_response
    
    # If not in cache, proceed with API call
    await redis_manager.add_to_history(session_id, new_message)
    

    URL = "https://llama-3-1-70b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1/chat/completions"
    OVH_API_KEY = ""
    
    headers = {
        #"Authorization": f"Bearer {OVH_API_KEY}",
        "Content-Type": "application/json"
    }

    payload = {
        "max_tokens": 2048,
        "messages": messages + [new_message],
        "model": "Meta-Llama-3_1-70B-Instruct",
        "temperature": 0,
    }

    # pretty print the payload to debug
    # print(json.dumps(payload, indent=4))

    async with httpx.AsyncClient() as client:
        response = await client.post(URL, json=payload, headers=headers)


    if response.status_code == 200:
        response_data = response.json()    
        choices = response_data["choices"]
        
        for choice in choices:
            result = choice["message"]["content"]
            
            # Save assistant's response to history
            await redis_manager.add_to_history(session_id, {
                "content": result,
                "name": "assistant",
                "role": "assistant"
            })
            
            # Save to cache
            await redis_manager.set_cache(prompt, result)
            
            return result
    else:
        print("Error:", response.text)
        return f"Error: {response.status_code}"

if __name__ == "__main__":
    async def main():
        redis_manager = RedisManager()
        while True:
            input_ = input('guest@trapster:~$ ')
            print(await make_query(redis_manager, '1234', input_))

    asyncio.run(main())

